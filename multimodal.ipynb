{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62ffc485-2a9a-4870-a36b-55274eb2a3be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/krish/anaconda3/lib/python3.11/site-packages (4.32.1)\n",
      "Requirement already satisfied: torch in /Users/krish/anaconda3/lib/python3.11/site-packages (2.1.2)\n",
      "Requirement already satisfied: speechrecognition in /Users/krish/anaconda3/lib/python3.11/site-packages (3.10.4)\n",
      "Requirement already satisfied: pydub in /Users/krish/anaconda3/lib/python3.11/site-packages (0.25.1)\n",
      "Requirement already satisfied: filelock in /Users/krish/anaconda3/lib/python3.11/site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /Users/krish/anaconda3/lib/python3.11/site-packages (from transformers) (0.15.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/krish/anaconda3/lib/python3.11/site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/krish/anaconda3/lib/python3.11/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/krish/anaconda3/lib/python3.11/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/krish/anaconda3/lib/python3.11/site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: requests in /Users/krish/anaconda3/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/krish/anaconda3/lib/python3.11/site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/krish/anaconda3/lib/python3.11/site-packages (from transformers) (0.3.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/krish/anaconda3/lib/python3.11/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/krish/anaconda3/lib/python3.11/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in /Users/krish/anaconda3/lib/python3.11/site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in /Users/krish/anaconda3/lib/python3.11/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/krish/anaconda3/lib/python3.11/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Users/krish/anaconda3/lib/python3.11/site-packages (from torch) (2023.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/krish/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/krish/anaconda3/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/krish/anaconda3/lib/python3.11/site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/krish/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/krish/anaconda3/lib/python3.11/site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/krish/anaconda3/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "#Importing necessary libraries\n",
    "!pip install transformers torch speechrecognition pydub\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "006e7dcb-7e43-4462-8b5b-0108bc2bd13c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gtts in /Users/krish/anaconda3/lib/python3.11/site-packages (2.5.1)\n",
      "Collecting playsound\n",
      "  Downloading playsound-1.3.0.tar.gz (7.7 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2.27 in /Users/krish/anaconda3/lib/python3.11/site-packages (from gtts) (2.32.2)\n",
      "Requirement already satisfied: click<8.2,>=7.1 in /Users/krish/anaconda3/lib/python3.11/site-packages (from gtts) (8.1.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/krish/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.27->gtts) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/krish/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.27->gtts) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/krish/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.27->gtts) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/krish/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.27->gtts) (2024.7.4)\n",
      "Building wheels for collected packages: playsound\n",
      "  Building wheel for playsound (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for playsound: filename=playsound-1.3.0-py3-none-any.whl size=7022 sha256=e87dc3d4b64fc70d6e8b561e447e9928290751421c37e67d3a44e8c8e46796c8\n",
      "  Stored in directory: /Users/krish/Library/Caches/pip/wheels/50/98/42/62753a9e1fb97579a0ce2f84f7db4c21c09d03bb2091e6cef4\n",
      "Successfully built playsound\n",
      "Installing collected packages: playsound\n",
      "Successfully installed playsound-1.3.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install  gtts playsound\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7e2d12e-b068-4563-90a3-ad8805950738",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydub in /Users/krish/anaconda3/lib/python3.11/site-packages (0.25.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pip install pydub \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7ee4347-7356-43ac-afcb-df3ab8dddac5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/krish/anaconda3/lib/python3.11/site-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "from pydub import AudioSegment\n",
    "\n",
    "def transcribe_audio(file_path):\n",
    "    # Convert the audio file to a format that SpeechRecognition can understand\n",
    "    audio = AudioSegment.from_file(file_path)\n",
    "    audio.export(\"converted.wav\", format=\"wav\")\n",
    "    \n",
    "    # Initialize the recognizer\n",
    "    recognizer = sr.Recognizer()\n",
    "    \n",
    "    # Load the audio file\n",
    "    with sr.AudioFile(\"converted.wav\") as source:\n",
    "        audio_data = recognizer.record(source)\n",
    "    \n",
    "    # Recognize the speech in the audio\n",
    "    try:\n",
    "        text = recognizer.recognize_google(audio_data)\n",
    "        print(f'Transcript: {text}')\n",
    "        return text\n",
    "    except sr.UnknownValueError:\n",
    "        print(\"Google Speech Recognition could not understand the audio\")\n",
    "        return None\n",
    "    except sr.RequestError as e:\n",
    "        print(f\"Could not request results from Google Speech Recognition service; {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44113642-5466-49d3-af51-1e474ea602c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/krish/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00910e9e-c538-449d-99c8-c62d8da753ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import speech_recognition as sr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83b4606a-24f9-4be4-89e5-245b891093f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9b13735-c4a5-4260-814a-2be8b35fedf8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Define the transcribe_audio function\n",
    "def transcribe_audio(file_path):\n",
    "    audio = AudioSegment.from_file(file_path)\n",
    "    audio.export(\"converted.wav\", format=\"wav\")\n",
    "    \n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.AudioFile(\"converted.wav\") as source:\n",
    "        audio_data = recognizer.record(source)\n",
    "    \n",
    "    try:\n",
    "        text = recognizer.recognize_google(audio_data)\n",
    "        print(f'Transcript: {text}')\n",
    "        return text\n",
    "    except sr.UnknownValueError:\n",
    "        print(\"Google Speech Recognition could not understand the audio\")\n",
    "        return None\n",
    "    except sr.RequestError as e:\n",
    "        print(f\"Could not request results from Google Speech Recognition service; {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21f24be5-a249-4c93-a720-93b70ffba6a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained BERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fd29e12-b987-4740-befa-0d2d7221b4f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the classify_intent function\n",
    "def classify_intent(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True)\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    predicted_class = torch.argmax(logits, dim=1).item()\n",
    "    return predicted_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60f8943d-e189-4d18-9835-9653b13b96b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define the intent labels\n",
    "intent_labels = {0: 'Placing an Order', 1: 'Account Inquiries', 2: 'Technical Support'}\n",
    "\n",
    "# Define the get_intent_label function\n",
    "def get_intent_label(predicted_class):\n",
    "    return intent_labels[predicted_class]\n",
    "\n",
    "# Define the handle_input function\n",
    "def handle_input(input_type, input_data):\n",
    "    if input_type == 'audio':\n",
    "        text = transcribe_audio(input_data)\n",
    "        if text is None:\n",
    "            return \"Could not transcribe audio.\"\n",
    "    elif input_type == 'text':\n",
    "        text = input_data\n",
    "    else:\n",
    "        raise ValueError('Invalid input type')\n",
    "    \n",
    "    predicted_class = classify_intent(text)\n",
    "    intent_label = get_intent_label(predicted_class)\n",
    "    return intent_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "548411c1-a437-4653-aa2b-509e47bb4cc6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: I want to know about my account\n",
      "Intent from audio: Placing an Order\n",
      "Intent from text: Placing an Order\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Example of audio.wav\n",
    "audio_file_path = 'audio.wav'\n",
    "text_input = 'I want to place an order for a new laptop.'\n",
    "\n",
    "# Handle audio input\n",
    "intent_from_audio = handle_input('audio', audio_file_path)\n",
    "print(f'Intent from audio: {intent_from_audio}')\n",
    "\n",
    "# Handle text input\n",
    "intent_from_text = handle_input('text', text_input)\n",
    "print(f'Intent from text: {intent_from_text}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c88bf09c-4565-4619-a20d-7e5a7804ec7b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gtts in /Users/krish/anaconda3/lib/python3.11/site-packages (2.5.1)\n",
      "Requirement already satisfied: requests<3,>=2.27 in /Users/krish/anaconda3/lib/python3.11/site-packages (from gtts) (2.32.2)\n",
      "Requirement already satisfied: click<8.2,>=7.1 in /Users/krish/anaconda3/lib/python3.11/site-packages (from gtts) (8.1.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/krish/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.27->gtts) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/krish/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.27->gtts) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/krish/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.27->gtts) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/krish/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.27->gtts) (2024.7.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install  gtts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae40bcb8-e34b-41c9-a26d-1e174a65c716",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from gtts import gTTS\n",
    "import os\n",
    "\n",
    "from playsound import playsound\n",
    "\n",
    "def text_to_speech(text, output_file=\"response.mp3\"):\n",
    "    tts = gTTS(text)\n",
    "    tts.save(output_file)\n",
    "    playsound(output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d373d80-950e-430a-b96e-0e952e173352",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "# Load pre-trained GPT-2 model and tokenizer for response generation\n",
    "gpt2_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "gpt2_model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "\n",
    "# Set padding token for GPT-2 tokenizer\n",
    "gpt2_tokenizer.pad_token = gpt2_tokenizer.eos_token\n",
    "\n",
    "def generate_response(intent, text):\n",
    "    prompt = f\"Intent: {intent}\\nUser: {text}\\nResponse:\"\n",
    "    inputs = gpt2_tokenizer.encode(prompt, return_tensors='pt', padding=True, truncation=True)\n",
    "    \n",
    "    # Create attention mask\n",
    "    attention_mask = inputs.ne(gpt2_tokenizer.pad_token_id).long()\n",
    "    \n",
    "    outputs = gpt2_model.generate(\n",
    "        inputs,\n",
    "        attention_mask=attention_mask,\n",
    "        max_length=100,\n",
    "        num_return_sequences=1,\n",
    "        pad_token_id=gpt2_tokenizer.eos_token_id\n",
    "    )\n",
    "    response = gpt2_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19cbcb1a-63a7-41b7-b154-5885feace352",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ConversationContext:\n",
    "    def __init__(self):\n",
    "        self.history = []\n",
    "\n",
    "    def update_context(self, user_input, intent, response):\n",
    "        self.history.append({'user_input': user_input, 'intent': intent, 'response': response})\n",
    "\n",
    "    def get_context(self):\n",
    "        return self.history\n",
    "\n",
    "context = ConversationContext()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1d8f35b-0849-4e48-a173-2bef4f256ee3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the handle_input function\n",
    "def handle_input(input_type, input_data):\n",
    "    if input_type == 'audio':\n",
    "        text = transcribe_audio(input_data)\n",
    "        if text is None:\n",
    "            return \"Could not transcribe audio.\"\n",
    "    elif input_type == 'text':\n",
    "        text = input_data\n",
    "    else:\n",
    "        raise ValueError('Invalid input type')\n",
    "    \n",
    "    predicted_class = classify_intent(text)\n",
    "    intent_label = get_intent_label(predicted_class)\n",
    "    \n",
    "    response = generate_response(intent_label, text)\n",
    "    context.update_context(text, intent_label, response)\n",
    "    \n",
    "    if input_type == 'audio':\n",
    "        text_to_speech(response)\n",
    "    else:\n",
    "        print(f'Response: {response}')\n",
    "    \n",
    "    return intent_label, response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b0ace61-acf3-4549-aa03-6ed719563950",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Example usage\n",
    "audio_file_path = 'audio.wav'\n",
    "text_input = 'I want to place an order.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0aca403-5438-4fe9-9105-a687dd4530da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: I want to know about my account\n",
      "Intent from audio: Placing an Order, Response: Intent: Placing an Order\n",
      "User: I want to know about my account\n",
      "Response: I want to know about your account\n",
      "User: I want to know about your account\n",
      "User: I want to know about your account\n",
      "User: I want to know about your account\n",
      "User: I want to know about your account\n",
      "User: I want to know about your account\n",
      "User: I want to know about your account\n",
      "User: I want to know about your account\n",
      "User:\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Handle audio input\n",
    "intent_from_audio, response_from_audio = handle_input('audio', audio_file_path)\n",
    "print(f'Intent from audio: {intent_from_audio}, Response: {response_from_audio}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "919828ac-8b69-4d3b-af5b-7572e5b1b898",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: Intent: Placing an Order\n",
      "User: I want to place an order.\n",
      "Response: I want to place an order.\n",
      "User: I want to place an order.\n",
      "User: I want to place an order.\n",
      "User: I want to place an order.\n",
      "User: I want to place an order.\n",
      "User: I want to place an order.\n",
      "User: I want to place an order.\n",
      "User: I want to place an order.\n",
      "User:\n",
      "Intent from text: Placing an Order, Response: Intent: Placing an Order\n",
      "User: I want to place an order.\n",
      "Response: I want to place an order.\n",
      "User: I want to place an order.\n",
      "User: I want to place an order.\n",
      "User: I want to place an order.\n",
      "User: I want to place an order.\n",
      "User: I want to place an order.\n",
      "User: I want to place an order.\n",
      "User: I want to place an order.\n",
      "User:\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Handle text input\n",
    "intent_from_text, response_from_text = handle_input('text', text_input)\n",
    "print(f'Intent from text: {intent_from_text}, Response: {response_from_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4a5617-54e6-46e6-ace9-715d6a16ecfc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efb1c26-ed0f-484e-845f-d9599d7f8a8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "55684cfc-5eaa-4454-b63a-69dfa4ec85c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c428b291-54ec-4ada-bcd3-4e99aab06519",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
